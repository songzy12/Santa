https://www.kaggle.com/c/santa-workshop-tour-2019/discussion/120160



[250x Faster Cost Function with Numba JIT](https://www.kaggle.com/nickel/250x-faster-cost-function-with-numba-jit): This kernel shows how to compile python functions to get blazing fast evaluation time (in fact, as fast as C code). This is a great way to learn about Numba, and made me realize how optimized Python can be if you are smart about how you build your functions (hint: ditch lists and make use of Numpy!).

[Fast Jonker-Volgenant algorithm](https://www.kaggle.com/pulkitmehtawork1985/fast-jonker-volgenant-algorithm): This kernel shows how to model the data we get, so that it can be used with a Linear Assignment Problem (LAP) solver. It is inspired from [this great blog post](https://opensourc.es/blog/kaggle-santa-2019), which solves the same problem, but in Julia (something else to learn eh).

[Better Initialization](https://www.kaggle.com/zzy990106/better-initialization-127711): The idea is really simple: randomly shuffle the choices of the family, then run the original assignment loops. This works surprisingly well, since it brings down the cost to a bit above 120k, without any complicated heuristic.

[
https://www.kaggle.com/zeta2191622/how-to-get-a-score-of-0-894-in-two-minutes](https://www.kaggle.com/zeta2191622/how-to-get-a-score-of-0-894-in-two-minutes)

https://www.kaggle.com/zfturbo/max-flow-with-min-cost-v2-0-9267

https://www.kaggle.com/golubev/simple-example-min-cost-flow